# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2021-02-11 23:24+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:1
#, no-wrap
msgid "---\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:10
#, no-wrap
msgid ""
"layout: blog\n"
"title: Scattered cache\n"
"permalink: /blog/:year/:month/:day/scattered-cache\n"
"date: '2017-07-03T13:49:00.001-07:00'\n"
"author: rvansa\n"
"tags: [ \"scattered cache\" ]\n"
"blogger_id: tag:blogger.com,1999:blog-5717179571414330874.post-7123650778935854208\n"
"blogger_orig_url: https://blog.infinispan.org/2017/07/scattered-cache.html\n"
"---\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:19
msgid "Infinispan strives for high throughput and low latency. Version 9.1.0.CR1 comes with a new cache mode - scattered cache - that's our answer to low round-trip times for write operations. Through a smart routing algorithm it guarantees that the write operation will result in only single RPC, where distributed caches with 2 owners would often use 2 RPCs. Scattered cache is resilient against single node failure (this is equivalent to distributed cache with 2 owners) and does not support transactions."
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:21
msgid "Declarative configuration is straigtforward:"
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:23
msgid "and programmatic is a piece of cake, too:"
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:33
msgid "What does the routing algorithm differently, then? In distributed cache, one node is always designated as the _primary_ owner and the others owners are _backups_. When a (non-owner) node does a write (invoke `cache.put(\"k\", \"v\")`), it sends the command to the primary owner, primary forwards it to the backups and the operation is completed only when all owners confirm this to the first node (_originator_). It's not possible to contact all owners in a single multinode RPC from the originator as the primary has to decide upon ordering in case of concurrent writes."
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:46
msgid "In scattered cache every node may be the backup. We don't designate backup owners in the routing table (also called _consistent hash_ for historical reasons), only primaries are set there. When a node does a write it sends the command to the primary owner and when this confirms the operation the originator stores the entry locally, effectively becoming a backup. That means that there can be more than 2 copies of the entry in the cluster, the others being outdated - but only temporarily, the other copies are eventually invalidated through a background process that does not slow down the synchronous writes. As you can see, this algorithm cannot be easily extended to multiple owners (keeping the performance characteristics) and therefore scattered cache does not support multiple backups."
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:56
msgid "In case of primary crash, the reconciliation process is somewhat more complex, because there's no central record telling who are the backups.  Instead, the new primary owner has to search all nodes and pick the last write - previous primary owner has assigned each entry a sequence number which makes this possible. And there are more technical difficulties - you can read about these in the https://github.com/infinispan/infinispan/blob/master/core/src/main/java/org/infinispan/scattered/package-info.java[design document] or in the https://github.com/infinispan/infinispan/blob/master/documentation/src/main/asciidoc/user_guide/clustering.adoc#scattered-mode[documentation]."
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:62
msgid "There is a con, of course. When reading an entry from a distributed cache, there is some chance that the entry will be located on this node (being one of the owners), and local reads are very fast. In scattered cache we always read from the primary node, as the local version of the entry might be already outdated. That halves the chance for a local read"
msgstr ""

#. type: Plain text
#: upstream/_posts/2017-07-03-scattered-cache.adoc:65
msgid "and this is the price you pay for faster writes. Don't worry too much, though - we have plans for http://infinispan.org/docs/stable/user_guide/user_guide.html#l1_caching[L1-like caching] that will make reads great again!"
msgstr ""
